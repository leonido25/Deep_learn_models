{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aLPwfTS2XLZ"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyBasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1)\n",
        "        self.BN1 = nn.BatchNorm2d(out_channels)\n",
        "        self.BN2 = nn.BatchNorm2d(out_channels)\n",
        "        if in_channels != out_channels or stride != 1:\n",
        "            self.skip = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "            nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        else:\n",
        "            self.skip = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.BN1(self.conv1(x)))\n",
        "        out = self.BN2(self.conv2(out))\n",
        "        skip_x = self.skip(x)\n",
        "        out = out + skip_x\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "veDlJK082alC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "      self.layer1 = nn.Sequential(MyBasicBlock(64, 64), MyBasicBlock(64, 64))\n",
        "      self.layer2 = nn.Sequential(MyBasicBlock(64, 128, stride=2), MyBasicBlock(128, 128))\n",
        "      self.layer3 = nn.Sequential(MyBasicBlock(128, 256, stride=2), MyBasicBlock(256, 256))\n",
        "      self.layer4 = nn.Sequential(MyBasicBlock(256, 512, stride=2), MyBasicBlock(512, 512))\n",
        "      self.BN1 = nn.BatchNorm2d(64)\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "      self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "      self.fc = nn.Linear(in_features=512, out_features=10)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.BN1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RqeJMFJN3Flk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
        "])\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZGAklb0yUL9",
        "outputId": "5e49dec1-ba1d-4dab-c03d-41e42caa017e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyResNet()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "uEiBFFAt0ECQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = next(iter(train_loader))[0]\n",
        "print(x.shape)  # [128, 3, 32, 32]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(x.to(device))\n",
        "    print(out.shape)  # [128, 10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6RNg63EKnGM",
        "outputId": "ca201711-db92-4422-c046-3364eadf80cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted==labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "metadata": {
        "id": "_5HXGgfYLFoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, test_loader, optimizer, criterion, device, num_epochs=5):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        acc = evaluate(model, test_loader, device)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {acc:.2f}%\")"
      ],
      "metadata": {
        "id": "45-Lx2Q1LPwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_loader, test_loader, optimizer, criterion, device, num_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuVLNgbELiaT",
        "outputId": "cfa82490-2f8b-4903-af6b-f5bc96c438ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.2774, Accuracy: 60.22%\n",
            "Epoch 2/5, Loss: 0.7383, Accuracy: 70.33%\n",
            "Epoch 3/5, Loss: 0.5116, Accuracy: 76.72%\n",
            "Epoch 4/5, Loss: 0.3703, Accuracy: 76.48%\n",
            "Epoch 5/5, Loss: 0.2399, Accuracy: 78.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujB2OxGhLtAr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}